{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from scipy import linalg\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "import torchvision.models as models\n",
    "from IPython.display import clear_output\n",
    "# from utils import gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "batch_size = 64\n",
    "image_size = 64\n",
    "# image_size = 128\n",
    "# image_size = 130\n",
    "in_channels = 3\n",
    "z_dim = 100\n",
    "epochs = 3000\n",
    "features_disc = 64\n",
    "features_gen = 64\n",
    "dropout = 0\n",
    "critic_iter = 5\n",
    "lambda_gp = 10\n",
    "# weight_clip = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"C:\\\\Users\\\\Seif Yasser\\\\Desktop\\\\Artificial intelligence\\\\Project\\\\Main-repo\\\\Image-Generation-Using-Generative-AI\\\\Shoes-Dataset-Colored\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomRotate:\n",
    "#     def __init__(self, degrees, fill=(255, 255, 255)):\n",
    "#         self.degrees = degrees\n",
    "#         self.fill = fill\n",
    "\n",
    "#     def __call__(self, img):\n",
    "#         # Convert PIL image to numpy array\n",
    "#         img_np = np.array(img)\n",
    "#         # Rotate the image\n",
    "#         rotated_img = Image.fromarray(np.uint8(img_np)).rotate(self.degrees, fillcolor=self.fill)\n",
    "#         return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate_probability = 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conditional_rotation(image):\n",
    "#     if random.random() < rotate_probability:\n",
    "#         return CustomRotate(degrees=random.randint(0,225))(image)\n",
    "#     else:\n",
    "#         return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Boot': 0, 'Sandal': 1, 'Shoe': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    # transforms.RandomHorizontalFlip(),             \n",
    "    # transforms.Lambda(conditional_rotation),  # Conditional rotation\n",
    "    # transforms.ColorJitter(brightness=0.2,         \n",
    "    #                        saturation=0,\n",
    "    #                        contrast=0,\n",
    "    #                        hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5 for _ in range(in_channels)], [0.5 for _ in range(in_channels)])\n",
    "])\n",
    "footwear = datasets.ImageFolder(root=dir, transform=transform)\n",
    "mapping = footwear.class_to_idx\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(footwear, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_tensor_images(image_tensor, num_images=1, size=(1, 28, 28)):\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "show_tensor_images(next(iter(train_loader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self, channel_imgs, features_d, num_of_classes, img_size, dropout_prob) -> None:\n",
    "        super(Critic, self).__init__()\n",
    "        # Input shape will be N x channel_imgs x 64x64\n",
    "        self.img_size = img_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.critic = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(channel_imgs+1, features_d, kernel_size=4, stride=2, padding=1), # 32x32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d*2, 4, 2, 1), # 16x16\n",
    "            self._block(features_d*2, features_d*4, 4, 2, 1), # 8x8\n",
    "            self._block(features_d*4, features_d*8, 4, 2, 1), # 4x4\n",
    "            nn.Conv2d(features_d*8, out_channels= 1, kernel_size=4, stride=2, padding=1), # 1 x 1\n",
    "            \n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_of_classes, img_size * img_size)\n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        embedding = self.embedding(labels).view(labels.shape[0], 1, self.img_size, self.img_size)\n",
    "        x = torch.cat([x, embedding], dim=1)\n",
    "        return self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g, num_classes, img_size, embed_size, dropout_prob = 0.5) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.generator = nn.Sequential(\n",
    "            # Input: N x z_dim x 1x1\n",
    "            self._block(z_dim + embed_size, features_g*16, 4, 1, 0), # N x features_g*16 x 16 \n",
    "            self._block(features_g*16, features_g*8, 4, 2, 1),  # N x features_g*8 x 8x8\n",
    "            self._block(features_g*8, features_g*4, 4, 2, 1),  # N x features_g*4 x 16x16\n",
    "            self._block(features_g*4, features_g*2, 4, 2, 1),  # N x features_g*2 x 32x32\n",
    "            nn.ConvTranspose2d(features_g*2, channels_img, kernel_size=4, stride=2, padding=1), # N x channels_img x 64x64\n",
    "            nn.Tanh(), # [-1, 1]       \n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_classes, embed_size)\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding), # deconvolution\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x, labels):\n",
    "        embedding = self.embedding(labels).unsqueeze(2).unsqueeze(3)\n",
    "        x = torch.cat([x, embedding], dim=1)\n",
    "        \n",
    "        return self.generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, labels,real, fake, device=\"cuda\"):\n",
    "    batch_size, C, H, W = real.shape\n",
    "    epsilon = torch.rand((batch_size, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * epsilon + fake * (1 - epsilon)\n",
    "    \n",
    "    mixed_scores = critic(interpolated_images, labels)\n",
    "    \n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    \n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "gen_embed = 100\n",
    "# gen_embed = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim, in_channels, features_gen, num_classes, image_size, gen_embed, dropout_prob= dropout).to(device)\n",
    "critic = Critic(in_channels, features_disc, num_classes, image_size, dropout_prob= dropout).to(device)\n",
    "intialize_weights(gen)\n",
    "intialize_weights(critic)\n",
    "# opt_gen = optim.RMSprop(gen.parameters(), lr=lr)\n",
    "# opt_critic = optim.RMSprop(critic.parameters(), lr=lr)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=lr, betas=(0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(32, z_dim, 1, 1)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "write_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen.load_state_dict(torch.load(\"./model_500/gen_500.pth\"))\n",
    "# disc.load_state_dict(torch.load(\"./model_500/disc_500.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (generator): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(200, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (4): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (embedding): Embedding(3, 100)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (critic): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (embedding): Embedding(3, 4096)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Seif Yasser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Seif Yasser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class InceptionV3(nn.Module):\n",
    "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
    "\n",
    "    # Index of default block of inception to return,\n",
    "    # corresponds to output of final average pooling\n",
    "    DEFAULT_BLOCK_INDEX = 3\n",
    "\n",
    "    # Maps feature dimensionality to their output blocks indices\n",
    "    BLOCK_INDEX_BY_DIM = {\n",
    "        64: 0,   # First max pooling features\n",
    "        192: 1,  # Second max pooling featurs\n",
    "        768: 2,  # Pre-aux classifier features\n",
    "        2048: 3  # Final average pooling features\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
    "                 resize_input=True,\n",
    "                 normalize_input=True,\n",
    "                 requires_grad=False):\n",
    "        \n",
    "        super(InceptionV3, self).__init__()\n",
    "\n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "\n",
    "        assert self.last_needed_block <= 3, \\\n",
    "            'Last possible output block index is 3'\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        \n",
    "        inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "        # Block 0: input to maxpool1\n",
    "        block0 = [\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        ]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "\n",
    "        # Block 1: maxpool1 to maxpool2\n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [\n",
    "                inception.Conv2d_3b_1x1,\n",
    "                inception.Conv2d_4a_3x3,\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "\n",
    "        # Block 2: maxpool2 to aux classifier\n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [\n",
    "                inception.Mixed_5b,\n",
    "                inception.Mixed_5c,\n",
    "                inception.Mixed_5d,\n",
    "                inception.Mixed_6a,\n",
    "                inception.Mixed_6b,\n",
    "                inception.Mixed_6c,\n",
    "                inception.Mixed_6d,\n",
    "                inception.Mixed_6e,\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "\n",
    "        # Block 3: aux classifier to final avgpool\n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [\n",
    "                inception.Mixed_7a,\n",
    "                inception.Mixed_7b,\n",
    "                inception.Mixed_7c,\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"Get Inception feature maps\n",
    "        Parameters\n",
    "        ----------\n",
    "        inp : torch.autograd.Variable\n",
    "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
    "            range (0, 1)\n",
    "        Returns\n",
    "        -------\n",
    "        List of torch.autograd.Variable, corresponding to the selected output\n",
    "        block, sorted ascending by index\n",
    "        \"\"\"\n",
    "        outp = []\n",
    "        x = inp\n",
    "\n",
    "        if self.resize_input:\n",
    "            x = F.interpolate(x,\n",
    "                              size=(299, 299),\n",
    "                              mode='bilinear',\n",
    "                              align_corners=False)\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
    "\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                outp.append(x)\n",
    "\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "\n",
    "        return outp\n",
    "    \n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "model = InceptionV3([block_idx])\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activation_statistics(images,model,batch_size=128, dims=2048,\n",
    "                    cuda=False):\n",
    "    model.eval()\n",
    "    act=np.empty((len(images), dims))\n",
    "    \n",
    "    if cuda:\n",
    "        batch=images.cuda()\n",
    "    else:\n",
    "        batch=images\n",
    "    pred = model(batch)[0]\n",
    "\n",
    "        # If model output is not scalar, apply global spatial average pooling.\n",
    "        # This happens if you choose a dimensionality not equal 2048.\n",
    "    if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "        pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "\n",
    "    act= pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fretchet(images_real,images_fake,model):\n",
    "     mu_1,std_1=calculate_activation_statistics(images_real,model,cuda=True)\n",
    "     mu_2,std_2=calculate_activation_statistics(images_fake,model,cuda=True)\n",
    "    \n",
    "     \"\"\"get fretched distance\"\"\"\n",
    "     fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
    "     return fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen.load_state_dict(torch.load(\"./WGANS-GP-2_lr_2e-4/WGANS-GP-2_400/gen_400.pth\"))\n",
    "\n",
    "# gen.eval()\n",
    "\n",
    "# # infere some images\n",
    "# label = torch.tensor([0], device=device).reshape()\n",
    "# noise = torch.randn(1, z_dim, 1, 1, device=device)\n",
    "# fake = gen(noise, label)\n",
    "# # enhance the image\n",
    "# fake = transforms.Resize((150, 150))(fake)\n",
    "# show_tensor_images(fake, size=(3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell Can be modified many times according to where the model stopped training\n",
    "# gen.load_state_dict(torch.load(\"./WGANS-GP-2_/WGANS-GP-2_149/gen_149.pth\"))\n",
    "# critic.load_state_dict(torch.load(\"./WGANS-GP-2_/WGANS-GP-2_149/critic_149.pth\"))\n",
    "# opt_critic.load_state_dict(torch.load(\"./WGANS-GP-2_/WGANS-GP-2_149/opt_critic_149.pth\"))\n",
    "# opt_gen.load_state_dict(torch.load(\"./WGANS-GP-2_/WGANS-GP-2_149/opt_gen_149.pth\"))\n",
    "# loss_critic = torch.load(\"./WGANS-GP-2_/WGANS-GP-2_149/losses_critic.pth\")\n",
    "# loss_gen = torch.load(\"./WGANS-GP-2_/WGANS-GP-2_149/losses_gen.pth\")\n",
    "# fid_scores_prev = torch.load(\"./WGANS-GP-2_/WGANS-GP-2_149/fid_scores.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (critic): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (embedding): Embedding(3, 4096)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.load_state_dict(torch.load(\"C:\\\\Users\\\\Seif Yasser\\\\Desktop\\\\Artificial intelligence\\\\Project\\\\Main-repo\\\\Image-Generation-Using-Generative-AI\\\\WGANS-GP-2_No-flip-64_\\\\WGANS-GP-2_No-flip-64_475\\\\gen_475.pth\"))\n",
    "critic.load_state_dict(torch.load(\"C:\\\\Users\\\\Seif Yasser\\\\Desktop\\\\Artificial intelligence\\\\Project\\\\Main-repo\\\\Image-Generation-Using-Generative-AI\\\\WGANS-GP-2_No-flip-64_\\\\WGANS-GP-2_No-flip-64_475\\\\critic_475.pth\"))\n",
    "gen.to(device)\n",
    "gen.float()\n",
    "gen.eval()\n",
    "\n",
    "critic.to(device)\n",
    "critic.float()\n",
    "critic.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_critic=[]\n",
    "losses_critic=torch.load(\"C:\\\\Users\\\\Seif Yasser\\\\Desktop\\\\Artificial intelligence\\\\Project\\\\Main-repo\\\\Image-Generation-Using-Generative-AI\\\\WGANS-GP-2_No-flip-64_\\\\WGANS-GP-2_No-flip-64_475\\\\losses_critic.pth\")\n",
    "losses_gen = []\n",
    "losses_gen = torch.load(\"C:\\\\Users\\\\Seif Yasser\\\\Desktop\\\\Artificial intelligence\\\\Project\\\\Main-repo\\\\Image-Generation-Using-Generative-AI\\\\WGANS-GP-2_No-flip-64_\\\\WGANS-GP-2_No-flip-64_475\\\\losses_gen.pth\")\n",
    "fid_scores = []\n",
    "fid_scores = torch.load(\"C:\\\\Users\\\\Seif Yasser\\\\Desktop\\\\Artificial intelligence\\\\Project\\\\Main-repo\\\\Image-Generation-Using-Generative-AI\\\\WGANS-GP-2_No-flip-64_\\\\WGANS-GP-2_No-flip-64_475\\\\fid_scores.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fid_scores.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 526/3000:   0%|          | 1/503 [00:00<05:49,  1.44it/s, Loss D=-2.39, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/3000] Batch 0/503 Loss D: -2.3854, loss G: 331.7905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 526/3000:  20%|        | 101/503 [00:43<03:01,  2.22it/s, Loss D=-3.63, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/3000] Batch 100/503 Loss D: -3.6255, loss G: 334.4977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 526/3000:  40%|      | 201/503 [01:26<02:16,  2.21it/s, Loss D=-2.27, Loss G=335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/3000] Batch 200/503 Loss D: -2.2681, loss G: 335.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 526/3000:  60%|    | 301/503 [02:09<01:31,  2.21it/s, Loss D=-2.72, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/3000] Batch 300/503 Loss D: -2.7229, loss G: 331.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 526/3000:  80%|  | 401/503 [02:52<00:46,  2.21it/s, Loss D=-2.4, Loss G=334] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/3000] Batch 400/503 Loss D: -2.4030, loss G: 334.1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 526/3000: 100%|| 501/503 [03:35<00:00,  2.21it/s, Loss D=-1.72, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/3000] Batch 500/503 Loss D: -1.7157, loss G: 332.9957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 526/3000: 100%|| 503/503 [03:36<00:00,  2.33it/s, Loss D=-1.85, Loss G=334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/3000] FID: 164.6060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 527/3000:   0%|          | 1/503 [00:00<07:12,  1.16it/s, Loss D=-2.29, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/3000] Batch 0/503 Loss D: -2.2890, loss G: 332.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 527/3000:  20%|        | 101/503 [00:43<03:02,  2.20it/s, Loss D=-3.54, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/3000] Batch 100/503 Loss D: -3.5382, loss G: 334.4029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 527/3000:  40%|      | 201/503 [01:26<02:16,  2.21it/s, Loss D=-2.35, Loss G=336]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/3000] Batch 200/503 Loss D: -2.3455, loss G: 335.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 527/3000:  60%|    | 301/503 [02:09<01:31,  2.20it/s, Loss D=-2.05, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/3000] Batch 300/503 Loss D: -2.0521, loss G: 334.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 527/3000:  80%|  | 401/503 [02:52<00:45,  2.22it/s, Loss D=-2.23, Loss G=331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/3000] Batch 400/503 Loss D: -2.2251, loss G: 331.4118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 527/3000: 100%|| 501/503 [03:35<00:00,  2.21it/s, Loss D=-1.96, Loss G=335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/3000] Batch 500/503 Loss D: -1.9612, loss G: 334.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 527/3000: 100%|| 503/503 [03:36<00:00,  2.32it/s, Loss D=-1.81, Loss G=334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/3000] FID: 173.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 528/3000:   0%|          | 1/503 [00:00<06:16,  1.33it/s, Loss D=-1.81, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/3000] Batch 0/503 Loss D: -1.8143, loss G: 333.5950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 528/3000:  20%|        | 101/503 [00:43<03:02,  2.20it/s, Loss D=-2.66, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/3000] Batch 100/503 Loss D: -2.6637, loss G: 333.9768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 528/3000:  40%|      | 201/503 [01:26<02:16,  2.21it/s, Loss D=-2.27, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/3000] Batch 200/503 Loss D: -2.2679, loss G: 332.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 528/3000:  60%|    | 301/503 [02:09<01:31,  2.21it/s, Loss D=-2.17, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/3000] Batch 300/503 Loss D: -2.1728, loss G: 332.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 528/3000:  80%|  | 401/503 [02:52<00:45,  2.22it/s, Loss D=-2.1, Loss G=330] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/3000] Batch 400/503 Loss D: -2.1039, loss G: 330.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 528/3000: 100%|| 501/503 [03:35<00:00,  2.21it/s, Loss D=-1.94, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/3000] Batch 500/503 Loss D: -1.9438, loss G: 332.4713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 528/3000: 100%|| 503/503 [03:36<00:00,  2.32it/s, Loss D=-2.6, Loss G=335] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [528/3000] FID: 174.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529/3000:   0%|          | 1/503 [00:00<05:56,  1.41it/s, Loss D=-2.68, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [529/3000] Batch 0/503 Loss D: -2.6783, loss G: 333.8363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529/3000:  20%|        | 101/503 [00:43<03:00,  2.22it/s, Loss D=-2.28, Loss G=335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [529/3000] Batch 100/503 Loss D: -2.2789, loss G: 334.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529/3000:  40%|      | 201/503 [01:26<02:17,  2.20it/s, Loss D=-1.37, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [529/3000] Batch 200/503 Loss D: -1.3714, loss G: 333.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529/3000:  60%|    | 301/503 [02:09<01:30,  2.22it/s, Loss D=-2.83, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [529/3000] Batch 300/503 Loss D: -2.8342, loss G: 333.4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529/3000:  80%|  | 401/503 [02:52<00:46,  2.22it/s, Loss D=-1.64, Loss G=335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [529/3000] Batch 400/503 Loss D: -1.6414, loss G: 335.3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529/3000: 100%|| 501/503 [03:35<00:00,  2.20it/s, Loss D=-2.14, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [529/3000] Batch 500/503 Loss D: -2.1430, loss G: 331.8896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529/3000: 100%|| 503/503 [03:36<00:00,  2.33it/s, Loss D=-2.81, Loss G=333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [529/3000] FID: 179.2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000:   0%|          | 1/503 [00:00<06:43,  1.24it/s, Loss D=-3.14, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/3000] Batch 0/503 Loss D: -3.1374, loss G: 332.1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000:  20%|        | 101/503 [00:43<03:01,  2.21it/s, Loss D=-2.33, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/3000] Batch 100/503 Loss D: -2.3296, loss G: 334.4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000:  40%|      | 201/503 [01:26<02:16,  2.21it/s, Loss D=-2.79, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/3000] Batch 200/503 Loss D: -2.7882, loss G: 334.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000:  60%|    | 301/503 [02:09<01:31,  2.22it/s, Loss D=-2.88, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/3000] Batch 300/503 Loss D: -2.8797, loss G: 333.8252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000:  80%|  | 401/503 [02:52<00:46,  2.21it/s, Loss D=-2.35, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/3000] Batch 400/503 Loss D: -2.3482, loss G: 333.2753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000: 100%|| 501/503 [03:35<00:00,  2.21it/s, Loss D=-2.2, Loss G=334] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/3000] Batch 500/503 Loss D: -2.2019, loss G: 334.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 530/3000: 100%|| 503/503 [03:36<00:00,  2.32it/s, Loss D=-1.95, Loss G=335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/3000] FID: 180.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 531/3000:   0%|          | 1/503 [00:00<06:49,  1.23it/s, Loss D=-2.04, Loss G=336]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/3000] Batch 0/503 Loss D: -2.0434, loss G: 335.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 531/3000:  20%|        | 101/503 [00:43<03:02,  2.20it/s, Loss D=-1.96, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/3000] Batch 100/503 Loss D: -1.9567, loss G: 334.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 531/3000:  40%|      | 201/503 [01:26<02:16,  2.21it/s, Loss D=-1.67, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/3000] Batch 200/503 Loss D: -1.6720, loss G: 332.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 531/3000:  60%|    | 301/503 [02:09<01:32,  2.19it/s, Loss D=-2.54, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/3000] Batch 300/503 Loss D: -2.5398, loss G: 333.3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 531/3000:  80%|  | 401/503 [02:52<00:46,  2.20it/s, Loss D=-2.33, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/3000] Batch 400/503 Loss D: -2.3324, loss G: 332.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 531/3000: 100%|| 501/503 [03:35<00:00,  2.20it/s, Loss D=-1.79, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/3000] Batch 500/503 Loss D: -1.7944, loss G: 334.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 531/3000: 100%|| 503/503 [03:36<00:00,  2.32it/s, Loss D=-2.44, Loss G=333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/3000] FID: 180.5479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 532/3000:   0%|          | 1/503 [00:00<06:58,  1.20it/s, Loss D=-1.94, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/3000] Batch 0/503 Loss D: -1.9407, loss G: 332.1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 532/3000:  20%|        | 101/503 [00:43<03:02,  2.21it/s, Loss D=-2.38, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/3000] Batch 100/503 Loss D: -2.3830, loss G: 334.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 532/3000:  40%|      | 201/503 [01:26<02:17,  2.19it/s, Loss D=-2.49, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/3000] Batch 200/503 Loss D: -2.4901, loss G: 332.8328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 532/3000:  60%|    | 301/503 [02:09<01:31,  2.20it/s, Loss D=-2.86, Loss G=335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/3000] Batch 300/503 Loss D: -2.8646, loss G: 334.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 532/3000:  80%|  | 401/503 [02:52<00:45,  2.22it/s, Loss D=-1.4, Loss G=334] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/3000] Batch 400/503 Loss D: -1.4004, loss G: 333.9758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 532/3000: 100%|| 501/503 [03:35<00:00,  2.21it/s, Loss D=-1.94, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/3000] Batch 500/503 Loss D: -1.9369, loss G: 332.7386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 532/3000: 100%|| 503/503 [03:36<00:00,  2.32it/s, Loss D=-2.21, Loss G=333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [532/3000] FID: 183.4215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 533/3000:   0%|          | 1/503 [00:00<06:37,  1.26it/s, Loss D=-2.25, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [533/3000] Batch 0/503 Loss D: -2.2548, loss G: 332.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 533/3000:  20%|        | 101/503 [00:43<03:02,  2.21it/s, Loss D=-2.11, Loss G=333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [533/3000] Batch 100/503 Loss D: -2.1058, loss G: 332.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 533/3000:  40%|      | 201/503 [01:26<02:17,  2.20it/s, Loss D=-2.73, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [533/3000] Batch 200/503 Loss D: -2.7273, loss G: 334.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 533/3000:  60%|    | 301/503 [02:09<01:31,  2.21it/s, Loss D=-1.73, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [533/3000] Batch 300/503 Loss D: -1.7299, loss G: 333.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 533/3000:  80%|  | 401/503 [02:52<00:46,  2.21it/s, Loss D=-2.01, Loss G=332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [533/3000] Batch 400/503 Loss D: -2.0084, loss G: 332.1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 533/3000: 100%|| 501/503 [03:39<00:01,  1.99it/s, Loss D=-1.86, Loss G=334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [533/3000] Batch 500/503 Loss D: -1.8553, loss G: 333.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 533/3000: 100%|| 503/503 [03:40<00:00,  2.29it/s, Loss D=-2.89, Loss G=334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [533/3000] FID: 174.7191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 534/3000:   0%|          | 1/503 [00:00<07:05,  1.18it/s, Loss D=-1.83, Loss G=335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [534/3000] Batch 0/503 Loss D: -1.8256, loss G: 334.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 534/3000:  18%|        | 89/503 [00:43<03:20,  2.06it/s, Loss D=-2.54, Loss G=335]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m cur_batch_size \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(critic_iter):\n\u001b[1;32m---> 11\u001b[0m     noise \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     fake \u001b[38;5;241m=\u001b[39m gen(noise, labels)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m     critic_real \u001b[38;5;241m=\u001b[39m critic(real, labels)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epoch = 475\n",
    "step = 0\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    tqdm_train_loader = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for batch_idx, (real, labels) in enumerate(tqdm_train_loader):\n",
    "        labels = labels.to(device)\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.shape[0]\n",
    "        for _ in range(critic_iter):\n",
    "            noise = torch.randn(cur_batch_size, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise, labels).to(device)\n",
    "            critic_real = critic(real, labels).reshape(-1)\n",
    "            critic_fake = critic(fake, labels).reshape(-1)\n",
    "            gp = gradient_penalty(critic, labels, real, fake, device=device)\n",
    "            loss_critic = (\n",
    "                -(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp # <- remove lambda_gp if not using WGAN-GP\n",
    "                )\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "        \n",
    "        losses_critic.append(loss_critic.item())\n",
    "\n",
    "        # for p in critic.parameters():\n",
    "        #     p.data.clamp_(-weight_clip, weight_clip)\n",
    "            \n",
    "        \n",
    "        ## Train Generator: min -E[critic(gen_fake)]\n",
    "        output = critic(fake, labels).reshape(-1)\n",
    "        loss_gen = -torch.mean(output)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        losses_gen.append(loss_gen.item())\n",
    "\n",
    "        # Update progress bar description\n",
    "        tqdm_train_loader.set_postfix({\"Loss D\": loss_critic.item(), \"Loss G\": loss_gen.item()})\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            tqdm_train_loader.write(\n",
    "                f\"Epoch [{epoch+1}/{epochs}] Batch {batch_idx}/{len(train_loader)} Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(noise, labels)\n",
    "                img_grid_real = make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = make_grid(fake[:32], normalize=True)\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                write_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "                step += 1\n",
    "\n",
    "    # Visualize and print losses after each epoch\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses_critic, label='Critic Loss')\n",
    "    plt.plot(losses_gen, label='Generator Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Epoch {epoch+1}/{epochs}: Critic and Generator Losses')\n",
    "    plt.legend()\n",
    "    os.makedirs(\"WGANS-GP-2_No-flip-64_/images/loss\", exist_ok=True)\n",
    "    plt.savefig(f\"WGANS-GP-2_No-flip-64_/images/loss/loss{epoch+1}.png\")\n",
    "    plt.close()\n",
    "    # Calculate and visualize FID every epoch\n",
    "    with torch.no_grad():\n",
    "        fake = gen(noise, labels)\n",
    "        fid = calculate_fretchet(real, fake, model)\n",
    "        fid_scores.append(fid)\n",
    "\n",
    "        # Visualize FID\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(epoch + 1), fid_scores, label='FID')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('FID')\n",
    "        plt.title('FID Score')\n",
    "        plt.legend()\n",
    "        os.makedirs(\"WGANS-GP-2_No-flip-64_/images/fid\", exist_ok=True)\n",
    "        plt.savefig(f\"WGANS-GP-2_No-flip-64_/images/fid/fid{epoch+1}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Print FID score\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] FID: {fid:.4f}\")\n",
    "\n",
    "    if (epoch+1) % 1 == 0 or epoch == 0:\n",
    "            gen.eval()\n",
    "            noise = torch.randn(32, z_dim, 1, 1).to(device)\n",
    "            fake = gen(noise, labels[:32])\n",
    "            img_grid_fake = make_grid(fake[:32], normalize=True)\n",
    "            plt.imshow(img_grid_fake.permute(1, 2, 0).cpu().numpy())\n",
    "            os.makedirs(\"WGANS-GP-2_No-flip-64_/images/fake\", exist_ok=True)\n",
    "            plt.savefig(f\"WGANS-GP-2_No-flip-64_/images/fake/fake{epoch+1}.png\")\n",
    "            plt.close()\n",
    "\n",
    "    # Save evaluation metrics, generator, Critic, and optimizers every 50 epochs\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        os.makedirs(f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}\", exist_ok=True)\n",
    "        \n",
    "        # Visualize FID\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(epoch + 1), fid_scores, label='FID')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('FID')\n",
    "        plt.title('FID Score')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/fid_plot.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(losses_critic, label='Critic Loss')\n",
    "        plt.plot(losses_gen, label='Generator Loss')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Epoch {epoch+1}/{epochs}: Critic and Generator Losses')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/losses_plot.png\")  \n",
    "        \n",
    "        plt.imsave(f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/fake_{epoch+1}.png\", img_grid_fake.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.close()\n",
    "        # Save evaluation metrics\n",
    "        evaluation_metrics = {\"FID\": fid_scores[-1]}\n",
    "        torch.save(evaluation_metrics, f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/evaluation_metrics.pth\")\n",
    "\n",
    "        # Save generator, Critic, and optimizers\n",
    "        torch.save(gen.state_dict(), f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/gen_{epoch+1}.pth\")\n",
    "        torch.save(critic.state_dict(), f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/critic_{epoch+1}.pth\")\n",
    "        torch.save(opt_gen.state_dict(), f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/opt_gen_{epoch+1}.pth\")\n",
    "        torch.save(opt_critic.state_dict(), f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/opt_critic_{epoch+1}.pth\")\n",
    "\n",
    "        # Save losses and evaluation scores to files\n",
    "        torch.save(losses_critic, f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/losses_critic.pth\")\n",
    "        torch.save(losses_gen, f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/losses_gen.pth\")\n",
    "        torch.save(fid_scores, f\"WGANS-GP-2_No-flip-64_/WGANS-GP-2_No-flip-64_{epoch+1}/fid_scores.pth\")\n",
    "    if (epoch+1) %25 == 0:\n",
    "        clear_output()\n",
    "    gen.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
